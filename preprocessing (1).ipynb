{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e27bd4a-f3a8-476f-9b80-9fa436f9e6e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:42:48.101064Z",
     "iopub.status.busy": "2025-10-09T06:42:48.100787Z",
     "iopub.status.idle": "2025-10-09T06:42:48.106322Z",
     "shell.execute_reply": "2025-10-09T06:42:48.105646Z",
     "shell.execute_reply.started": "2025-10-09T06:42:48.101041Z"
    }
   },
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python3\n",
    "# %pip install numpy scikit-learn opencv-python-headless\n",
    "# \"\"\"\n",
    "# A script to process images for multiple classes from specific folders.\n",
    "\n",
    "# How it works:\n",
    "# 1.  Loops through a list of predefined class names.\n",
    "# 2.  For each class, reads images from 'defect' and 'non-defect' subfolders.\n",
    "# 3.  Assigns label '1' to defect images and '0' to non-defect images.\n",
    "# 4.  Resizes and normalizes all images for that class.\n",
    "# 5.  Splits the data into training and validation sets.\n",
    "# 6.  Saves the processed data into class-specific subdirectories.\n",
    "# \"\"\"\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import pickle\n",
    "# from glob import glob\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from typing import Tuple, List, Dict, Any, Optional\n",
    "\n",
    "# # ===============================================================\n",
    "# #                       CONFIGURATION\n",
    "# #          --->>> EDIT THESE VARIABLES <<<---\n",
    "# # ===============================================================\n",
    "\n",
    "# # 1. List of class subdirectories to process.\n",
    "# CLASS_NAMES = [\"lighting_panel\", \"shifted_grab_handle\", \"frosted_window\"]\n",
    "\n",
    "# # 2. Path where the processed data will be saved.\n",
    "# OUTPUT_DIR = 'processed_data_multi_class/'\n",
    "\n",
    "# # 3. The size to resize all images to (height, width).\n",
    "# IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# # 4. The percentage of data to use for validation (e.g., 0.2 = 20%).\n",
    "# VAL_SPLIT = 0.3\n",
    "\n",
    "# # ===============================================================\n",
    "\n",
    "\n",
    "# def load_and_preprocess_data_for_class(class_name: str) -> Tuple[Optional[Tuple[np.ndarray, np.ndarray]], Optional[Tuple[np.ndarray, np.ndarray]]]:\n",
    "#     \"\"\"\n",
    "#     Loads images for a single class, preprocesses them,\n",
    "#     and splits into train/validation sets.\n",
    "#     \"\"\"\n",
    "#     images: List[np.ndarray] = []\n",
    "#     labels: List[int] = []\n",
    "\n",
    "#     # Define the paths for the current class\n",
    "#     path_non_defect = f'Dataset/AR_Train/non-defect/{class_name}'\n",
    "#     path_defect = f'Dataset/AR_Train/defect/{class_name}'\n",
    "    \n",
    "#     classes_to_process = {\n",
    "#         'non-defect': {'path': path_non_defect, 'label': 0},\n",
    "#         'defect': {'path': path_defect, 'label': 1}\n",
    "#     }\n",
    "\n",
    "#     print(f\"--- Processing class: {class_name} ---\")\n",
    "#     for sub_class, info in classes_to_process.items():\n",
    "#         folder_path = info['path']\n",
    "#         label = info['label']\n",
    "        \n",
    "#         if not os.path.isdir(folder_path):\n",
    "#             print(f\"  WARNING: Directory not found, skipping: {folder_path}\")\n",
    "#             continue\n",
    "\n",
    "#         image_paths = glob(os.path.join(folder_path, '*.jpg'))\n",
    "        \n",
    "#         print(f\"  Found {len(image_paths)} images for '{sub_class}'\")\n",
    "\n",
    "#         for path in image_paths:\n",
    "#             try:\n",
    "#                 img = cv2.imread(path)\n",
    "#                 if img is None:\n",
    "#                     print(f\"  WARNING: Could not read image, skipping: {path}\")\n",
    "#                     continue\n",
    "                \n",
    "#                 # Resize and normalize\n",
    "#                 img_resized = cv2.resize(img, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "#                 img_normalized = img_resized.astype(np.float32) / 255.0\n",
    "                \n",
    "#                 images.append(img_normalized)\n",
    "#                 labels.append(label)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"  ERROR: Failed processing {path}: {e}\")\n",
    "\n",
    "#     if not images:\n",
    "#         print(f\"  ERROR: No images were loaded for class '{class_name}'. Aborting this class.\")\n",
    "#         return (None, None), (None, None)\n",
    "\n",
    "#     X = np.array(images)\n",
    "#     y = np.array(labels)\n",
    "\n",
    "#     # Split data into training and validation sets\n",
    "#     X_train, X_val, y_train, y_val = train_test_split(\n",
    "#         X, y, test_size=VAL_SPLIT, random_state=42, stratify=y\n",
    "#     )\n",
    "    \n",
    "#     print(f\"  Data split complete. Training: {len(X_train)}, Validation: {len(X_val)}\")\n",
    "#     return (X_train, y_train), (X_val, y_val)\n",
    "\n",
    "# def save_data(data: Dict[str, Any], output_path: str, filename: str) -> None:\n",
    "#     \"\"\"Saves data to a file using pickle.\"\"\"\n",
    "#     os.makedirs(output_path, exist_ok=True)\n",
    "#     filepath = os.path.join(output_path, filename)\n",
    "#     with open(filepath, 'wb') as f:\n",
    "#         pickle.dump(data, f)\n",
    "#     print(f\"  Data saved to: {filepath}\")\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Main execution function to loop through all classes.\"\"\"\n",
    "#     for class_name in CLASS_NAMES:\n",
    "#         # Create class-specific output directories\n",
    "#         output_class_dir = os.path.join(OUTPUT_DIR, class_name)\n",
    "#         output_train_dir = os.path.join(output_class_dir, 'train')\n",
    "#         output_val_dir = os.path.join(output_class_dir, 'val')\n",
    "\n",
    "#         # Load and process data for the current class\n",
    "#         (X_train, y_train), (X_val, y_val) = load_and_preprocess_data_for_class(class_name)\n",
    "        \n",
    "#         if X_train is not None and y_train is not None:\n",
    "#             save_data({'images': X_train, 'labels': y_train}, output_train_dir, 'train_data.pkl')\n",
    "#             save_data({'images': X_val, 'labels': y_val}, output_val_dir, 'val_data.pkl')\n",
    "#             print(f\"--- Finished processing for class: {class_name} ---\\n\")\n",
    "#         else:\n",
    "#             print(f\"--- Failed to process class: {class_name} ---\\n\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5698ca-5eda-4e21-8bd5-553a199b422b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T06:42:48.107679Z",
     "iopub.status.busy": "2025-10-09T06:42:48.107396Z",
     "iopub.status.idle": "2025-10-09T06:50:52.739786Z",
     "shell.execute_reply": "2025-10-09T06:50:52.739011Z",
     "shell.execute_reply.started": "2025-10-09T06:42:48.107652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.7.2)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Using cached opencv_python_headless-4.12.0.88-cp37-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (54.0 MB)\n",
      "Using cached numpy-2.2.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.5 MB)\n",
      "Installing collected packages: numpy, opencv-python-headless\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [opencv-python-headless]v-python-headless]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "amazon-sagemaker-jupyter-ai-q-developer 1.2.7 requires onnxruntime<2,>=1.15.0, which is not installed.\n",
      "autogluon-multimodal 1.4.0 requires nvidia-ml-py3<8.0,>=7.352.0, which is not installed.\n",
      "amazon-sagemaker-jupyter-ai-q-developer 1.2.7 requires numpy<=2.0.1, but you have numpy 2.2.6 which is incompatible.\n",
      "amazon-sagemaker-sql-magic 0.1.4 requires numpy<2, but you have numpy 2.2.6 which is incompatible.\n",
      "autogluon-multimodal 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.56.1 which is incompatible.\n",
      "autogluon-timeseries 1.4.0 requires transformers[sentencepiece]<4.50,>=4.38.0, but you have transformers 4.56.1 which is incompatible.\n",
      "gluonts 0.16.2 requires numpy<2.2,>=1.16, but you have numpy 2.2.6 which is incompatible.\n",
      "langchain-aws 0.2.19 requires boto3>=1.37.24, but you have boto3 1.37.1 which is incompatible.\n",
      "sagemaker 2.245.0 requires numpy==1.26.4, but you have numpy 2.2.6 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-2.2.6 opencv-python-headless-4.12.0.88\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "--- Loading data for class: lighting_panel ---\n",
      "  Found 1158 images for 'non-defect'\n",
      "  Found 818 images for 'defect'\n",
      "  Successfully loaded 1976 total images for this class.\n",
      "\n",
      "--- Creating 3-fold splits for class: lighting_panel ---\n",
      "  Processing Fold 1/3...\n",
      "    Training set size: 1317\n",
      "    Validation set size: 659\n",
      "  Data saved to: processed_data_multi_class_3_fold/lighting_panel/fold_1/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/lighting_panel/fold_1/val_data.pkl\n",
      "  Processing Fold 2/3...\n",
      "    Training set size: 1317\n",
      "    Validation set size: 659\n",
      "  Data saved to: processed_data_multi_class_3_fold/lighting_panel/fold_2/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/lighting_panel/fold_2/val_data.pkl\n",
      "  Processing Fold 3/3...\n",
      "    Training set size: 1318\n",
      "    Validation set size: 658\n",
      "  Data saved to: processed_data_multi_class_3_fold/lighting_panel/fold_3/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/lighting_panel/fold_3/val_data.pkl\n",
      "--- Finished processing for class: lighting_panel ---\n",
      "\n",
      "--- Loading data for class: shifted_grab_handle ---\n",
      "  Found 201 images for 'non-defect'\n",
      "  Found 222 images for 'defect'\n",
      "  Successfully loaded 423 total images for this class.\n",
      "\n",
      "--- Creating 3-fold splits for class: shifted_grab_handle ---\n",
      "  Processing Fold 1/3...\n",
      "    Training set size: 282\n",
      "    Validation set size: 141\n",
      "  Data saved to: processed_data_multi_class_3_fold/shifted_grab_handle/fold_1/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/shifted_grab_handle/fold_1/val_data.pkl\n",
      "  Processing Fold 2/3...\n",
      "    Training set size: 282\n",
      "    Validation set size: 141\n",
      "  Data saved to: processed_data_multi_class_3_fold/shifted_grab_handle/fold_2/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/shifted_grab_handle/fold_2/val_data.pkl\n",
      "  Processing Fold 3/3...\n",
      "    Training set size: 282\n",
      "    Validation set size: 141\n",
      "  Data saved to: processed_data_multi_class_3_fold/shifted_grab_handle/fold_3/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/shifted_grab_handle/fold_3/val_data.pkl\n",
      "--- Finished processing for class: shifted_grab_handle ---\n",
      "\n",
      "--- Loading data for class: frosted_window ---\n",
      "  Found 553 images for 'non-defect'\n",
      "  Found 471 images for 'defect'\n",
      "  Successfully loaded 1024 total images for this class.\n",
      "\n",
      "--- Creating 3-fold splits for class: frosted_window ---\n",
      "  Processing Fold 1/3...\n",
      "    Training set size: 682\n",
      "    Validation set size: 342\n",
      "  Data saved to: processed_data_multi_class_3_fold/frosted_window/fold_1/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/frosted_window/fold_1/val_data.pkl\n",
      "  Processing Fold 2/3...\n",
      "    Training set size: 683\n",
      "    Validation set size: 341\n",
      "  Data saved to: processed_data_multi_class_3_fold/frosted_window/fold_2/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/frosted_window/fold_2/val_data.pkl\n",
      "  Processing Fold 3/3...\n",
      "    Training set size: 683\n",
      "    Validation set size: 341\n",
      "  Data saved to: processed_data_multi_class_3_fold/frosted_window/fold_3/train_data.pkl\n",
      "  Data saved to: processed_data_multi_class_3_fold/frosted_window/fold_3/val_data.pkl\n",
      "--- Finished processing for class: frosted_window ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "%pip install numpy scikit-learn opencv-python-headless\n",
    "\"\"\"\n",
    "A script to process images for multiple classes and prepare\n",
    "data for 3-fold cross-validation.\n",
    "\n",
    "How it works:\n",
    "1.  Loops through a list of predefined class names.\n",
    "2.  For each class, reads all 'defect' (label 1) and 'non-defect' (label 0) images.\n",
    "3.  Resizes and normalizes all images.\n",
    "4.  Uses StratifiedKFold to split the data into 3 folds for cross-validation.\n",
    "5.  Each fold consists of a training set (~67%) and a validation set (~33%).\n",
    "6.  Saves the processed data for each fold into class-specific subdirectories.\n",
    "\"\"\"\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "from glob import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from typing import Tuple, List, Dict, Any, Optional\n",
    "\n",
    "# ===============================================================\n",
    "#                       CONFIGURATION\n",
    "#             --->>> EDIT THESE VARIABLES <<<---\n",
    "# ===============================================================\n",
    "\n",
    "# 1. List of class subdirectories to process.\n",
    "CLASS_NAMES = [\"lighting_panel\", \"shifted_grab_handle\", \"frosted_window\"]\n",
    "\n",
    "# 2. Path where the processed data will be saved.\n",
    "OUTPUT_DIR = 'processed_data_multi_class_3_fold/'\n",
    "\n",
    "# 3. The size to resize all images to (height, width).\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "# 4. The number of folds for cross-validation.\n",
    "N_FOLDS = 3\n",
    "\n",
    "# ===============================================================\n",
    "\n",
    "\n",
    "def load_all_data_for_class(class_name: str) -> Optional[Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Loads and preprocesses all images for a single class.\n",
    "    \"\"\"\n",
    "    images: List[np.ndarray] = []\n",
    "    labels: List[int] = []\n",
    "\n",
    "    # Define the paths for the current class\n",
    "    path_non_defect = f'Dataset/AR_Train/non-defect/{class_name}'\n",
    "    path_defect = f'Dataset/AR_Train/defect/{class_name}'\n",
    "    \n",
    "    classes_to_process = {\n",
    "        'non-defect': {'path': path_non_defect, 'label': 0},\n",
    "        'defect': {'path': path_defect, 'label': 1}\n",
    "    }\n",
    "\n",
    "    print(f\"--- Loading data for class: {class_name} ---\")\n",
    "    for sub_class, info in classes_to_process.items():\n",
    "        folder_path = info['path']\n",
    "        label = info['label']\n",
    "        \n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"  WARNING: Directory not found, skipping: {folder_path}\")\n",
    "            continue\n",
    "\n",
    "        image_paths = glob(os.path.join(folder_path, '*.jpg'))\n",
    "        \n",
    "        print(f\"  Found {len(image_paths)} images for '{sub_class}'\")\n",
    "\n",
    "        for path in image_paths:\n",
    "            try:\n",
    "                img = cv2.imread(path)\n",
    "                if img is None:\n",
    "                    print(f\"  WARNING: Could not read image, skipping: {path}\")\n",
    "                    continue\n",
    "                \n",
    "                # Resize and normalize\n",
    "                img_resized = cv2.resize(img, (IMAGE_SIZE[1], IMAGE_SIZE[0]))\n",
    "                img_normalized = img_resized.astype(np.float32) / 255.0\n",
    "                \n",
    "                images.append(img_normalized)\n",
    "                labels.append(label)\n",
    "            except Exception as e:\n",
    "                print(f\"  ERROR: Failed processing {path}: {e}\")\n",
    "\n",
    "    if not images:\n",
    "        print(f\"  ERROR: No images were loaded for class '{class_name}'. Aborting this class.\")\n",
    "        return None\n",
    "\n",
    "    X = np.array(images)\n",
    "    y = np.array(labels)\n",
    "    \n",
    "    print(f\"  Successfully loaded {len(X)} total images for this class.\")\n",
    "    return X, y\n",
    "\n",
    "def save_data(data: Dict[str, Any], output_path: str, filename: str) -> None:\n",
    "    \"\"\"Saves data to a file using pickle.\"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    filepath = os.path.join(output_path, filename)\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"  Data saved to: {filepath}\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function to loop through all classes and create k-fold splits.\"\"\"\n",
    "    for class_name in CLASS_NAMES:\n",
    "        # Load all data for the current class\n",
    "        data = load_all_data_for_class(class_name)\n",
    "        \n",
    "        if data is None:\n",
    "            print(f\"--- Failed to process class: {class_name} ---\\n\")\n",
    "            continue\n",
    "            \n",
    "        X, y = data\n",
    "        \n",
    "        # Initialize Stratified K-Fold\n",
    "        skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "        # Loop through each fold\n",
    "        print(f\"\\n--- Creating {N_FOLDS}-fold splits for class: {class_name} ---\")\n",
    "        for fold_idx, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n",
    "            fold_num = fold_idx + 1\n",
    "            print(f\"  Processing Fold {fold_num}/{N_FOLDS}...\")\n",
    "            \n",
    "            # Create data splits for the current fold\n",
    "            X_train, X_val = X[train_indices], X[val_indices]\n",
    "            y_train, y_val = y[train_indices], y[val_indices]\n",
    "            \n",
    "            print(f\"    Training set size: {len(X_train)}\")\n",
    "            print(f\"    Validation set size: {len(X_val)}\")\n",
    "\n",
    "            # Define output directory for the current fold\n",
    "            output_fold_dir = os.path.join(OUTPUT_DIR, class_name, f'fold_{fold_num}')\n",
    "            \n",
    "            # Save the training and validation data for the fold\n",
    "            save_data({'images': X_train, 'labels': y_train}, output_fold_dir, 'train_data.pkl')\n",
    "            save_data({'images': X_val, 'labels': y_val}, output_fold_dir, 'val_data.pkl')\n",
    "            \n",
    "        print(f\"--- Finished processing for class: {class_name} ---\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "594b1f5b-b377-40c4-884a-e0f1b27ff57f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:51:36.914975Z",
     "iopub.status.busy": "2025-10-10T06:51:36.914727Z",
     "iopub.status.idle": "2025-10-10T06:51:40.497004Z",
     "shell.execute_reply": "2025-10-10T06:51:40.496479Z",
     "shell.execute_reply.started": "2025-10-10T06:51:36.914954Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import vgg16, VGG16_Weights\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "# For timestamping\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Set timezone for Lahore, Pakistan\n",
    "pk_timezone = pytz.timezone(\"Asia/Karachi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "070c58db-df40-4e05-9280-c0ee60308e51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:53:55.627862Z",
     "iopub.status.busy": "2025-10-10T06:53:55.627557Z",
     "iopub.status.idle": "2025-10-10T06:53:55.632188Z",
     "shell.execute_reply": "2025-10-10T06:53:55.631569Z",
     "shell.execute_reply.started": "2025-10-10T06:53:55.627839Z"
    }
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # --- Paths ---\n",
    "    # The base directory where all class folders are located\n",
    "    base_data_dir = 'processed_data_multi_class_3_fold/'\n",
    "    # The base directory where all trained models will be saved\n",
    "    base_output_dir = 'trained_models_multi_class/'\n",
    "\n",
    "    # --- Classes to Train ---\n",
    "    # The script will train one model for each class in this list.\n",
    "    CLASS_NAMES = [\"lighting_panel\", \"shifted_grab_handle\", \"frosted_window\"]\n",
    "\n",
    "    # --- Model Parameters ---\n",
    "    # This is a binary classification (defect vs. non-defect) for each class\n",
    "    num_classes = 2\n",
    "    N_FOLDS = 3\n",
    "\n",
    "    # --- ADL Specific Parameters ---\n",
    "    drop_rate = 0.4\n",
    "    drop_threshold = 0.8\n",
    "    adl_alpha = 0.1\n",
    "\n",
    "    # --- Training Hyperparameters ---\n",
    "    epochs = 50\n",
    "    batch_size = 16\n",
    "    lr = 0.001\n",
    "    num_workers = 2\n",
    "\n",
    "# Instantiate the config object\n",
    "config = Config()\n",
    "\n",
    "# Create the base output directory if it doesn't exist\n",
    "os.makedirs(config.base_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d69d23d-59b2-4195-9eb4-281903ff1aa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:53:58.048109Z",
     "iopub.status.busy": "2025-10-10T06:53:58.047845Z",
     "iopub.status.idle": "2025-10-10T06:53:58.053480Z",
     "shell.execute_reply": "2025-10-10T06:53:58.052874Z",
     "shell.execute_reply.started": "2025-10-10T06:53:58.048089Z"
    }
   },
   "outputs": [],
   "source": [
    "class ADL(nn.Module):\n",
    "    def __init__(self, in_channels: int, drop_rate: float, drop_threshold: float):\n",
    "        super().__init__()\n",
    "        if not (0.0 <= drop_rate < 1.0):\n",
    "            raise ValueError(\"drop_rate must be in the range [0, 1)\")\n",
    "        if not (0.0 <= drop_threshold < 1.0):\n",
    "            raise ValueError(\"drop_threshold must be in the range [0, 1)\")\n",
    "\n",
    "        self.drop_rate = drop_rate\n",
    "        self.drop_threshold = drop_threshold\n",
    "        self.attention_conv = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, feature_maps: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        attention_map = self.attention_conv(feature_maps)\n",
    "        attention_map = torch.sigmoid(attention_map)\n",
    "\n",
    "        if self.training:\n",
    "            B, _, H, W = attention_map.shape\n",
    "            attention_flat = attention_map.view(B, -1)\n",
    "            M = int(H * W * self.drop_rate)\n",
    "            if M <= 0:\n",
    "                return feature_maps, attention_map\n",
    "            _, topk_indices = torch.topk(attention_flat, k=M, dim=1)\n",
    "            drop_mask = torch.ones_like(attention_flat)\n",
    "            drop_mask.scatter_(dim=1, index=topk_indices, value=0)\n",
    "            drop_mask = drop_mask.view(B, 1, H, W)\n",
    "        else:\n",
    "            drop_mask = (attention_map < self.drop_threshold).float()\n",
    "\n",
    "        dropped_feature_maps = feature_maps * drop_mask\n",
    "        return dropped_feature_maps, attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c1625b4-f5e4-4bab-9665-90bcde73e435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:54:00.419766Z",
     "iopub.status.busy": "2025-10-10T06:54:00.419509Z",
     "iopub.status.idle": "2025-10-10T06:54:00.424835Z",
     "shell.execute_reply": "2025-10-10T06:54:00.424181Z",
     "shell.execute_reply.started": "2025-10-10T06:54:00.419746Z"
    }
   },
   "outputs": [],
   "source": [
    "class PreprocessedDataset(Dataset):\n",
    "    def __init__(self, pkl_path: str):\n",
    "        print(f\"Loading data from {pkl_path}...\")\n",
    "        try:\n",
    "            with open(pkl_path, 'rb') as f:\n",
    "                self.data = pickle.load(f)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"ERROR: Data file not found at {pkl_path}\")\n",
    "            raise\n",
    "        self.images = self.data['images']\n",
    "        self.labels = self.data['labels']\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        print(\"Data loaded successfully.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_bgr = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        image_rgb = image_bgr[..., ::-1].copy() # BGR to RGB\n",
    "        image_tensor = self.transform(image_rgb)\n",
    "        label_tensor = torch.tensor(label, dtype=torch.long)\n",
    "        return image_tensor, label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fc7d90e-b599-4b2d-9a42-1d3b6f90ab58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:54:01.795898Z",
     "iopub.status.busy": "2025-10-10T06:54:01.795636Z",
     "iopub.status.idle": "2025-10-10T06:54:01.800335Z",
     "shell.execute_reply": "2025-10-10T06:54:01.799710Z",
     "shell.execute_reply.started": "2025-10-10T06:54:01.795877Z"
    }
   },
   "outputs": [],
   "source": [
    "class ADLModel(nn.Module):\n",
    "    def __init__(self, num_classes: int, drop_rate: float, drop_threshold: float):\n",
    "        super().__init__()\n",
    "        vgg_full = vgg16(weights=VGG16_Weights.IMAGENET1K_V1)\n",
    "        self.backbone = vgg_full.features\n",
    "        in_channels = 512\n",
    "        self.adl_layer = ADL(in_channels, drop_rate, drop_threshold)\n",
    "        self.classifier = nn.Conv2d(in_channels, num_classes, kernel_size=1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        feature_maps = self.backbone(x)\n",
    "        dropped_maps, attention_map = self.adl_layer(feature_maps)\n",
    "        logits = self.classifier(dropped_maps)\n",
    "        logits = F.adaptive_avg_pool2d(logits, (1, 1))\n",
    "        logits = logits.squeeze(-1).squeeze(-1)\n",
    "        return logits, attention_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32e8af25-dde6-4b7e-8f59-e476d37dab89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:54:04.119781Z",
     "iopub.status.busy": "2025-10-10T06:54:04.119524Z",
     "iopub.status.idle": "2025-10-10T06:54:04.128781Z",
     "shell.execute_reply": "2025-10-10T06:54:04.128212Z",
     "shell.execute_reply.started": "2025-10-10T06:54:04.119760Z"
    }
   },
   "outputs": [],
   "source": [
    "# def train_one_epoch(model, dataloader, criterion_cls, optimizer, device, adl_alpha):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     running_loss_cls = 0.0\n",
    "#     running_loss_adl = 0.0\n",
    "#     correct_predictions = 0\n",
    "#     total_samples = 0\n",
    "#     for inputs, labels in dataloader:\n",
    "#         inputs, labels = inputs.to(device), labels.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         logits, attention_map = model(inputs)\n",
    "#         loss_cls = criterion_cls(logits, labels)\n",
    "#         loss_adl = torch.mean(attention_map)\n",
    "#         total_loss = loss_cls + adl_alpha * loss_adl\n",
    "#         total_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         running_loss += total_loss.item() * inputs.size(0)\n",
    "#         running_loss_cls += loss_cls.item() * inputs.size(0)\n",
    "#         running_loss_adl += loss_adl.item() * inputs.size(0)\n",
    "#         _, preds = torch.max(logits, 1)\n",
    "#         correct_predictions += torch.sum(preds == labels.data)\n",
    "#         total_samples += labels.size(0)\n",
    "#     epoch_loss = running_loss / total_samples\n",
    "#     epoch_acc = correct_predictions.double() / total_samples\n",
    "#     epoch_loss_cls = running_loss_cls / total_samples\n",
    "#     epoch_loss_adl = running_loss_adl / total_samples\n",
    "#     return epoch_loss, epoch_acc, epoch_loss_cls, epoch_loss_adl\n",
    "def train_one_epoch(model, dataloader, criterion_cls, optimizer, device, adl_alpha):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_loss_cls = 0.0\n",
    "    running_loss_adl = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits, attention_map = model(inputs)\n",
    "        \n",
    "        loss_cls = criterion_cls(logits, labels)\n",
    "        loss_adl = torch.mean(attention_map)\n",
    "        total_loss = loss_cls + adl_alpha * loss_adl\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += total_loss.item() * inputs.size(0)\n",
    "        running_loss_cls += loss_cls.item() * inputs.size(0)\n",
    "        running_loss_adl += loss_adl.item() * inputs.size(0)\n",
    "        \n",
    "        _, preds = torch.max(logits, 1)\n",
    "        correct_predictions += torch.sum(preds == labels.data)\n",
    "        total_samples += labels.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / total_samples\n",
    "    epoch_acc = correct_predictions.double() / total_samples\n",
    "    epoch_loss_cls = running_loss_cls / total_samples\n",
    "    epoch_loss_adl = running_loss_adl / total_samples\n",
    "    \n",
    "    # CORRECTED RETURN STATEMENT: Returns a dictionary instead of a tuple\n",
    "    return {\n",
    "        \"loss\": epoch_loss,\n",
    "        \"accuracy\": epoch_acc.item(), # Use .item() to get a standard Python number\n",
    "        \"cls_loss\": epoch_loss_cls,\n",
    "        \"adl_loss\": epoch_loss_adl\n",
    "    }\n",
    "\n",
    "# def validate(model, dataloader, criterion_cls, device):\n",
    "#     model.eval()\n",
    "#     running_loss = 0.0\n",
    "#     correct_predictions = 0\n",
    "#     total_samples = 0\n",
    "#     with torch.no_grad():\n",
    "#         for inputs, labels in dataloader:\n",
    "#             inputs, labels = inputs.to(device), labels.to(device)\n",
    "#             logits, _ = model(inputs)\n",
    "#             loss = criterion_cls(logits, labels)\n",
    "#             running_loss += loss.item() * inputs.size(0)\n",
    "#             _, preds = torch.max(logits, 1)\n",
    "#             correct_predictions += torch.sum(preds == labels.data)\n",
    "#             total_samples += labels.size(0)\n",
    "#     epoch_loss = running_loss / total_samples\n",
    "#     epoch_acc = correct_predictions.double() / total_samples\n",
    "#     return epoch_loss, epoch_acc\n",
    "def validate(model, dataloader, criterion_cls, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            logits, _ = model(inputs)\n",
    "            loss = criterion_cls(logits, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(logits, 1)\n",
    "            \n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    epoch_loss = running_loss / len(all_labels)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
    "    accuracy = np.sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "\n",
    "    # CORRECTED RETURN STATEMENT: Now returns a dictionary\n",
    "    return {\n",
    "        \"loss\": epoch_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"labels\": all_labels,\n",
    "        \"predictions\": all_preds\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef039f6b-f70c-4a01-8887-aba916845a36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:54:04.844156Z",
     "iopub.status.busy": "2025-10-10T06:54:04.843887Z",
     "iopub.status.idle": "2025-10-10T06:54:04.847887Z",
     "shell.execute_reply": "2025-10-10T06:54:04.847333Z",
     "shell.execute_reply.started": "2025-10-10T06:54:04.844136Z"
    }
   },
   "outputs": [],
   "source": [
    "# # --- Setup ---\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # --- Data Loading ---\n",
    "# train_dataset = PreprocessedDataset(os.path.join(config.data_dir, 'train', 'train_data.pkl'))\n",
    "# val_dataset = PreprocessedDataset(os.path.join(config.data_dir, 'val', 'val_data.pkl'))\n",
    "# train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "# # --- Model, Loss, Optimizer ---\n",
    "# model = ADLModel(\n",
    "#     num_classes=config.num_classes,\n",
    "#     drop_rate=config.drop_rate,\n",
    "#     drop_threshold=config.drop_threshold\n",
    "# ).to(device)\n",
    "\n",
    "# criterion_cls = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "# scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "\n",
    "# # --- Training Loop ---\n",
    "# best_val_acc = 0.0\n",
    "# print(\"\\nStarting training...\")\n",
    "# start_time_pk = datetime.now(pk_timezone)\n",
    "# print(f\"Start Time (Lahore): {start_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "\n",
    "# for epoch in range(config.epochs):\n",
    "#     print(f\"\\n--- Epoch {epoch+1}/{config.epochs} ---\")\n",
    "#     train_loss, train_acc, loss_cls, loss_adl = train_one_epoch(\n",
    "#         model, train_loader, criterion_cls, optimizer, device, config.adl_alpha)\n",
    "#     print(f\"Train | Total Loss: {train_loss:.4f} | Cls Loss: {loss_cls:.4f} | ADL Loss: {loss_adl:.4f} | Acc: {train_acc:.4f}\")\n",
    "\n",
    "#     val_loss, val_acc = validate(model, val_loader, criterion_cls, device)\n",
    "#     print(f\"Val   | Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "    \n",
    "#     scheduler.step()\n",
    "\n",
    "#     if val_acc > best_val_acc:\n",
    "#         best_val_acc = val_acc\n",
    "#         torch.save(model.state_dict(), os.path.join(config.output_dir, 'best_model_adl.pth'))\n",
    "#         print(f\"New best model saved with val acc: {best_val_acc:.4f}\")\n",
    "\n",
    "# end_time_pk = datetime.now(pk_timezone)\n",
    "# print(f\"\\n--- Training Finished ---\")\n",
    "# print(f\"End Time (Lahore): {end_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "# print(f\"Total training duration: {end_time_pk - start_time_pk}\")\n",
    "# print(f\"Best validation accuracy achieved: {best_val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c993a52-ed2d-422d-b153-77b0519b5d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:54:05.758357Z",
     "iopub.status.busy": "2025-10-10T06:54:05.758107Z",
     "iopub.status.idle": "2025-10-10T06:54:05.762502Z",
     "shell.execute_reply": "2025-10-10T06:54:05.761933Z",
     "shell.execute_reply.started": "2025-10-10T06:54:05.758337Z"
    }
   },
   "outputs": [],
   "source": [
    "# # --- Setup ---\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(f\"Using device: {device}\")\n",
    "\n",
    "# # Store results for each class\n",
    "# results = {}\n",
    "\n",
    "# # Loop through each class name defined in the config\n",
    "# for class_name in config.CLASS_NAMES:\n",
    "#     print(f\"\\n========================================================\")\n",
    "#     print(f\"        STARTING TRAINING FOR CLASS: {class_name}\")\n",
    "#     print(f\"========================================================\")\n",
    "\n",
    "#     # --- Create class-specific paths ---\n",
    "#     current_data_dir = os.path.join(config.base_data_dir, class_name)\n",
    "#     current_output_dir = os.path.join(config.base_output_dir, class_name)\n",
    "#     os.makedirs(current_output_dir, exist_ok=True)\n",
    "\n",
    "#     # --- Data Loading for the current class ---\n",
    "#     train_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'train', 'train_data.pkl'))\n",
    "#     val_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'val', 'val_data.pkl'))\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "#     # --- Model, Loss, Optimizer (re-initialized for each class) ---\n",
    "#     model = ADLModel(\n",
    "#         num_classes=config.num_classes,\n",
    "#         drop_rate=config.drop_rate,\n",
    "#         drop_threshold=config.drop_threshold\n",
    "#     ).to(device)\n",
    "\n",
    "#     criterion_cls = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "#     scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "\n",
    "#     # --- Training Loop for the current class ---\n",
    "#     best_val_acc = 0.0\n",
    "#     start_time_pk = datetime.now(pk_timezone)\n",
    "#     print(f\"Start Time (Lahore): {start_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "\n",
    "#     for epoch in range(config.epochs):\n",
    "#         print(f\"\\n--- Epoch {epoch+1}/{config.epochs} ---\")\n",
    "#         train_loss, train_acc, loss_cls, loss_adl = train_one_epoch(\n",
    "#             model, train_loader, criterion_cls, optimizer, device, config.adl_alpha)\n",
    "#         print(f\"Train | Total Loss: {train_loss:.4f} | Cls Loss: {loss_cls:.4f} | ADL Loss: {loss_adl:.4f} | Acc: {train_acc:.4f}\")\n",
    "\n",
    "#         val_loss, val_acc = validate(model, val_loader, criterion_cls, device)\n",
    "#         print(f\"Val   | Loss: {val_loss:.4f} | Acc: {val_acc:.4f}\")\n",
    "\n",
    "#         scheduler.step()\n",
    "\n",
    "#         if val_acc > best_val_acc:\n",
    "#             best_val_acc = val_acc\n",
    "#             torch.save(model.state_dict(), os.path.join(current_output_dir, 'best_model_adl.pth'))\n",
    "#             print(f\"New best model for '{class_name}' saved with val acc: {best_val_acc:.4f}\")\n",
    "\n",
    "#     end_time_pk = datetime.now(pk_timezone)\n",
    "#     results[class_name] = best_val_acc\n",
    "#     print(f\"\\n--- Training for '{class_name}' Finished ---\")\n",
    "#     print(f\"End Time (Lahore): {end_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "#     print(f\"Total training duration: {end_time_pk - start_time_pk}\")\n",
    "#     print(f\"Best validation accuracy for '{class_name}': {best_val_acc:.4f}\")\n",
    "\n",
    "\n",
    "# # --- Final Summary ---\n",
    "# print(\"\\n========================================================\")\n",
    "# print(\"              ALL TRAINING RUNS COMPLETE\")\n",
    "# print(\"========================================================\")\n",
    "# for class_name, acc in results.items():\n",
    "#     print(f\"  - Best validation accuracy for '{class_name}': {acc:.4f}\")\n",
    "# print(\"========================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc6aa63a-22ac-4abd-8fa2-1d24465b2178",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:54:06.672805Z",
     "iopub.status.busy": "2025-10-10T06:54:06.672552Z",
     "iopub.status.idle": "2025-10-10T06:54:16.843137Z",
     "shell.execute_reply": "2025-10-10T06:54:16.842370Z",
     "shell.execute_reply.started": "2025-10-10T06:54:06.672786Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "========================================================\n",
      "       STARTING 3-FOLD CV FOR CLASS: lighting_panel\n",
      "========================================================\n",
      "\n",
      "--- Starting Fold 1/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/lighting_panel/fold_1/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/lighting_panel/fold_1/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for 'lighting_panel'. Starting training from scratch.\n",
      "\n",
      "--- Epoch 1/50 ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'criterion_cls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 263\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, Config\u001b[38;5;241m.\u001b[39mepochs):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mConfig\u001b[38;5;241m.\u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 263\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m train_one_epoch(model, train_loader, \u001b[43mcriterion_cls\u001b[49m, optimizer, device, Config\u001b[38;5;241m.\u001b[39madl_alpha)\n\u001b[1;32m    264\u001b[0m     val_metrics \u001b[38;5;241m=\u001b[39m validate(model, val_loader, criterion_cls, device)\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;66;03m# Log metrics\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'criterion_cls' is not defined"
     ]
    },
    {
     "data": {
      "application/sagemaker-interactive-debugging": {
       "cell_id": "dc6aa63a-22ac-4abd-8fa2-1d24465b2178",
       "debugging_info_folder": "/home/sagemaker-user/shared/.temp_sagemaker_unified_studio_debugging_info/dc6aa63a-22ac-4abd-8fa2-1d24465b2178",
       "instruction_file": "/home/sagemaker-user/shared/.temp_sagemaker_unified_studio_debugging_info/ipython_debugging_sop.txt",
       "magic_command": "no_magic",
       "session_type": "python_3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Setup ---\n",
    "# In Cell 1\n",
    "\n",
    "# Make sure this line includes all four functions\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "results = {}\n",
    "\n",
    "# --- Main Loop ---\n",
    "# for class_name in config.CLASS_NAMES:\n",
    "#     print(f\"\\n========================================================\")\n",
    "#     print(f\"        STARTING TRAINING FOR CLASS: {class_name}\")\n",
    "#     print(f\"========================================================\")\n",
    "\n",
    "#     # --- Paths and History Initialization ---\n",
    "#     current_data_dir = os.path.join(config.base_data_dir, class_name)\n",
    "#     current_output_dir = os.path.join(config.base_output_dir, class_name)\n",
    "#     os.makedirs(current_output_dir, exist_ok=True)\n",
    "    \n",
    "#     history = {\n",
    "#         'train_loss': [], 'train_acc': [],\n",
    "#         'val_loss': [], 'val_acc': [],\n",
    "#         'val_precision': [], 'val_recall': [], 'val_f1': []\n",
    "#     }\n",
    "#     best_val_metrics = None\n",
    "\n",
    "#     # --- Data Loading ---\n",
    "#     train_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'train', 'train_data.pkl'))\n",
    "#     val_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'val', 'val_data.pkl'))\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "#     # --- Model, Loss, Optimizer ---\n",
    "#     model = ADLModel(config.num_classes, config.drop_rate, config.drop_threshold).to(device)\n",
    "#     criterion_cls = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "#     scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "\n",
    "#     # --- Training Loop ---\n",
    "#     best_val_acc = 0.0\n",
    "#     start_time_pk = datetime.now(pk_timezone)\n",
    "#     print(f\"Start Time (Lahore): {start_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "\n",
    "#     for epoch in range(config.epochs):\n",
    "#         print(f\"\\n--- Epoch {epoch+1}/{config.epochs} ---\")\n",
    "        \n",
    "#         train_metrics = train_one_epoch(model, train_loader, criterion_cls, optimizer, device, config.adl_alpha)\n",
    "#         val_metrics = validate(model, val_loader, criterion_cls, device)\n",
    "        \n",
    "#         # Log metrics\n",
    "#         history['train_loss'].append(train_metrics['loss'])\n",
    "#         history['train_acc'].append(train_metrics['accuracy'])\n",
    "#         history['val_loss'].append(val_metrics['loss'])\n",
    "#         history['val_acc'].append(val_metrics['accuracy'])\n",
    "#         history['val_precision'].append(val_metrics['precision'])\n",
    "#         history['val_recall'].append(val_metrics['recall'])\n",
    "#         history['val_f1'].append(val_metrics['f1_score'])\n",
    "        \n",
    "#         print(f\"Train | Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}\")\n",
    "#         print(f\"Val   | Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1_score']:.4f}\")\n",
    "        \n",
    "#         scheduler.step()\n",
    "\n",
    "#         if val_metrics['accuracy'] > best_val_acc:\n",
    "#             best_val_acc = val_metrics['accuracy']\n",
    "#             best_val_metrics = val_metrics\n",
    "#             torch.save(model.state_dict(), os.path.join(current_output_dir, 'best_model_adl.pth'))\n",
    "#             print(f\"New best model for '{class_name}' saved with val acc: {best_val_acc:.4f}\")\n",
    "\n",
    "#     end_time_pk = datetime.now(pk_timezone)\n",
    "#     results[class_name] = best_val_acc\n",
    "#     print(f\"\\n--- Training for '{class_name}' Finished ---\")\n",
    "#     print(f\"End Time (Lahore): {end_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "#     print(f\"Best validation accuracy for '{class_name}': {best_val_acc:.4f}\")\n",
    "    \n",
    "#     # --- Save Metrics and Generate Plots ---\n",
    "    \n",
    "#     # Create a DataFrame from the history\n",
    "   \n",
    "# # --- Final Summary ---\n",
    "# print(\"\\n========================================================\")\n",
    "# print(\"              ALL TRAINING RUNS COMPLETE\")\n",
    "# print(\"========================================================\")\n",
    "# for class_name, acc in results.items():\n",
    "#     print(f\"  - Best validation accuracy for '{class_name}': {acc:.4f}\")\n",
    "# print(\"========================================================\")\n",
    "# for class_name in Config.CLASS_NAMES:\n",
    "#     print(f\"\\n========================================================\")\n",
    "#     print(f\"        STARTING TRAINING FOR CLASS: {class_name}\")\n",
    "#     print(f\"========================================================\")\n",
    "\n",
    "#     # --- Paths and Directory Setup ---\n",
    "#     current_data_dir = os.path.join(Config.base_data_dir, class_name)\n",
    "#     current_output_dir = os.path.join(Config.base_output_dir, class_name)\n",
    "#     os.makedirs(current_output_dir, exist_ok=True)\n",
    "    \n",
    "#     # --- Data Loading ---\n",
    "#     train_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'train', 'train_data.pkl'))\n",
    "#     val_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'val', 'val_data.pkl'))\n",
    "#     train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers)\n",
    "#     val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
    "\n",
    "#     # --- Model, Loss, Optimizer ---\n",
    "#     model = ADLModel(Config.num_classes, Config.drop_rate, Config.drop_threshold).to(device)\n",
    "#     criterion_cls = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=Config.lr)\n",
    "#     scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "\n",
    "#     # --- Checkpoint Loading Logic ---\n",
    "#     checkpoint_path = os.path.join(current_output_dir, 'checkpoint.pth')\n",
    "#     start_epoch = 0\n",
    "#     best_val_acc = 0.0\n",
    "#     history = {\n",
    "#         'train_loss': [], 'train_acc': [],\n",
    "#         'val_loss': [], 'val_acc': [],\n",
    "#         'val_precision': [], 'val_recall': [], 'val_f1': []\n",
    "#     }\n",
    "\n",
    "#     if os.path.exists(checkpoint_path):\n",
    "#         print(f\"✅ Resuming training for '{class_name}' from checkpoint.\")\n",
    "#         # Load checkpoint onto the correct device\n",
    "#         # Tell torch.load it's okay to unpickle other Python objects besides tensors\n",
    "#         checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "#         model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#         scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "#         start_epoch = checkpoint['epoch'] + 1\n",
    "#         history = checkpoint['history']\n",
    "#         best_val_acc = checkpoint['best_val_acc']\n",
    "#         print(f\"   Resumed from epoch {start_epoch}. Best validation accuracy so far: {best_val_acc:.4f}\")\n",
    "#     else:\n",
    "#         print(f\"ℹ️ No checkpoint found for '{class_name}'. Starting training from scratch.\")\n",
    "\n",
    "\n",
    "#     # --- Training Loop ---\n",
    "#     best_val_metrics = None\n",
    "#     start_time_pk = datetime.now(pk_timezone)\n",
    "#     print(f\"Start Time (Lahore): {start_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "\n",
    "#     # **MODIFIED**: Start the loop from 'start_epoch'\n",
    "#     for epoch in range(start_epoch, Config.epochs):\n",
    "#         print(f\"\\n--- Epoch {epoch+1}/{Config.epochs} ---\")\n",
    "        \n",
    "#         train_metrics = train_one_epoch(model, train_loader, criterion_cls, optimizer, device, Config.adl_alpha)\n",
    "#         val_metrics = validate(model, val_loader, criterion_cls, device)\n",
    "        \n",
    "#         # Log metrics\n",
    "#         history['train_loss'].append(train_metrics['loss'])\n",
    "#         history['train_acc'].append(train_metrics['accuracy'])\n",
    "#         history['val_loss'].append(val_metrics['loss'])\n",
    "#         history['val_acc'].append(val_metrics['accuracy'])\n",
    "#         history['val_precision'].append(val_metrics['precision'])\n",
    "#         history['val_recall'].append(val_metrics['recall'])\n",
    "#         history['val_f1'].append(val_metrics['f1_score'])\n",
    "        \n",
    "#         print(f\"Train | Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}\")\n",
    "#         print(f\"Val   | Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1_score']:.4f}\")\n",
    "        \n",
    "#         scheduler.step()\n",
    "\n",
    "#         if val_metrics['accuracy'] > best_val_acc:\n",
    "#             best_val_acc = val_metrics['accuracy']\n",
    "#             best_val_metrics = val_metrics\n",
    "#             torch.save(model.state_dict(), os.path.join(current_output_dir, 'best_model_adl.pth'))\n",
    "#             print(f\"New best model for '{class_name}' saved with val acc: {best_val_acc:.4f}\")\n",
    "\n",
    "#         # --- Save Checkpoint After Each Epoch ---\n",
    "#         torch.save({\n",
    "#             'epoch': epoch,\n",
    "#             'model_state_dict': model.state_dict(),\n",
    "#             'optimizer_state_dict': optimizer.state_dict(),\n",
    "#             'scheduler_state_dict': scheduler.state_dict(),\n",
    "#             'best_val_acc': best_val_acc,\n",
    "#             'history': history,\n",
    "#         }, checkpoint_path)\n",
    "\n",
    "#     end_time_pk = datetime.now(pk_timezone)\n",
    "#     results[class_name] = best_val_acc\n",
    "#     print(f\"\\n--- Training for '{class_name}' Finished ---\")\n",
    "#     print(f\"End Time (Lahore): {end_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "#     print(f\"Best validation accuracy for '{class_name}': {best_val_acc:.4f}\")\n",
    "    \n",
    "#     # --- Save Metrics and Generate Plots ---\n",
    "#     # Create a DataFrame from the history\n",
    "#     # ... (your existing code for plotting and saving metrics) ...\n",
    "    \n",
    "# # --- Final Summary ---\n",
    "# print(\"\\n========================================================\")\n",
    "# print(\"               ALL TRAINING RUNS COMPLETE\")\n",
    "# print(\"========================================================\")\n",
    "# for class_name, acc in results.items():\n",
    "#     print(f\"  - Best validation accuracy for '{class_name}': {acc:.4f}\")\n",
    "# print(\"========================================================\")\n",
    "\n",
    "# A list to store the final F1 score (or accuracy) from each fold\n",
    "all_fold_results = []\n",
    "\n",
    "for class_name in Config.CLASS_NAMES:\n",
    "    print(f\"\\n========================================================\")\n",
    "    print(f\"       STARTING {Config.N_FOLDS}-FOLD CV FOR CLASS: {class_name}\")\n",
    "    print(f\"========================================================\")\n",
    "    \n",
    "    class_data_dir = os.path.join(Config.base_data_dir, class_name)\n",
    "    class_output_dir = os.path.join(Config.base_output_dir, class_name)\n",
    "\n",
    "    # --- NEW: Outer loop for each fold ---\n",
    "    for fold_idx in range(1, Config.N_FOLDS + 1):\n",
    "        print(f\"\\n--- Starting Fold {fold_idx}/{Config.N_FOLDS} ---\")\n",
    "\n",
    "        # --- MODIFIED: Paths now point to the specific fold's data and output ---\n",
    "        current_data_dir = os.path.join(class_data_dir, f'fold_{fold_idx}')\n",
    "        current_output_dir = os.path.join(class_output_dir, f'fold_{fold_idx}')\n",
    "        os.makedirs(current_output_dir, exist_ok=True)\n",
    "        \n",
    "        # --- Data Loading for the current fold ---\n",
    "        train_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'train_data.pkl'))\n",
    "        val_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'val_data.pkl'))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=Config.batch_size, shuffle=False)\n",
    "\n",
    "        # --- IMPORTANT: Re-initialize model and optimizer for each fold ---\n",
    "        model = ADLModel(Config.num_classes, Config.drop_rate, Config.drop_threshold).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=Config.lr)\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "\n",
    "        # --- Checkpointing logic (as you wrote it) would go here ---\n",
    "        # It will now save/load checkpoints inside the fold-specific output directory\n",
    "        checkpoint_path = os.path.join(current_output_dir, 'checkpoint.pth')\n",
    "        # ... (your checkpoint loading code)\n",
    "       \n",
    "        start_epoch = 0\n",
    "        best_val_acc = 0.0\n",
    "        history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'val_loss': [], 'val_acc': [],\n",
    "            'val_precision': [], 'val_recall': [], 'val_f1': []\n",
    "        }\n",
    "    \n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(f\"✅ Resuming training for '{class_name}' from checkpoint.\")\n",
    "            # Load checkpoint onto the correct device\n",
    "            # Tell torch.load it's okay to unpickle other Python objects besides tensors\n",
    "            checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "            start_epoch = checkpoint['epoch'] + 1\n",
    "            history = checkpoint['history']\n",
    "            best_val_acc = checkpoint['best_val_acc']\n",
    "            print(f\"   Resumed from epoch {start_epoch}. Best validation accuracy so far: {best_val_acc:.4f}\")\n",
    "        else:\n",
    "            print(f\"ℹ️ No checkpoint found for '{class_name}'. Starting training from scratch.\")\n",
    "    \n",
    "\n",
    "\n",
    "        # --- Training Loop (your existing code for epochs) ---\n",
    "        best_val_f1 = 0.0 # Or best_val_acc\n",
    "        for epoch in range(start_epoch, Config.epochs):\n",
    "            print(f\"\\n--- Epoch {epoch+1}/{Config.epochs} ---\")\n",
    "            \n",
    "            train_metrics = train_one_epoch(model, train_loader, criterion_cls, optimizer, device, Config.adl_alpha)\n",
    "            val_metrics = validate(model, val_loader, criterion_cls, device)\n",
    "            \n",
    "            # Log metrics\n",
    "            history['train_loss'].append(train_metrics['loss'])\n",
    "            history['train_acc'].append(train_metrics['accuracy'])\n",
    "            history['val_loss'].append(val_metrics['loss'])\n",
    "            history['val_acc'].append(val_metrics['accuracy'])\n",
    "            history['val_precision'].append(val_metrics['precision'])\n",
    "            history['val_recall'].append(val_metrics['recall'])\n",
    "            history['val_f1'].append(val_metrics['f1_score'])\n",
    "            \n",
    "            print(f\"Train | Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}\")\n",
    "            print(f\"Val   | Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1_score']:.4f}\")\n",
    "            \n",
    "            scheduler.step()\n",
    "    \n",
    "            if val_metrics['accuracy'] > best_val_acc:\n",
    "                best_val_acc = val_metrics['accuracy']\n",
    "                best_val_metrics = val_metrics\n",
    "                torch.save(model.state_dict(), os.path.join(current_output_dir, 'best_model_adl.pth'))\n",
    "                print(f\"New best model for '{class_name}' saved with val acc: {best_val_acc:.4f}\")\n",
    "    \n",
    "            # --- Save Checkpoint After Each Epoch ---\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'history': history,\n",
    "            }, checkpoint_path)\n",
    "    \n",
    "    end_time_pk = datetime.now(pk_timezone)\n",
    "    results[class_name] = best_val_acc\n",
    "    print(f\"\\n--- Training for '{class_name}' Finished ---\")\n",
    "    print(f\"End Time (Lahore): {end_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "    print(f\"Best validation accuracy for '{class_name}': {best_val_acc:.4f}\")\n",
    "        \n",
    "        # --- Save Metrics and Generate Plots ---\n",
    "        # Create a DataFrame from the history\n",
    "        # ... (your existing code for plotting and saving metrics) ...\n",
    "        \n",
    "    # --- Final Summary ---\n",
    "    print(\"\\n========================================================\")\n",
    "    print(\"               ALL TRAINING RUNS COMPLETE\")\n",
    "    print(\"========================================================\")\n",
    "    for class_name, acc in results.items():\n",
    "        print(f\"  - Best validation accuracy for '{class_name}': {acc:.4f}\")\n",
    "    print(\"========================================================\")\n",
    "           # ... (your for loop over epochs)\n",
    "           #     ... (your training and validation calls)\n",
    "            #    ... (save best model to current_output_dir)\n",
    "        \n",
    "        # --- Store the best result for this fold ---\n",
    "    print(f\"--- Best F1 Score for Fold {fold_idx}: {best_val_f1:.4f} ---\")\n",
    "    all_fold_results.append(best_val_f1)\n",
    "\n",
    "    # --- Aggregate and report the final average score for the class ---\n",
    "    average_score = sum(all_fold_results) / len(all_fold_results)\n",
    "    print(f\"\\n--- Average Cross-Validation F1 Score for '{class_name}': {average_score:.4f} ---\")\n",
    "    all_fold_results.clear() # Reset for the next class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfd96c7c-b2c3-4a1e-bdcd-75f983e6f87a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-10T06:56:35.001743Z",
     "iopub.status.busy": "2025-10-10T06:56:35.001487Z",
     "iopub.status.idle": "2025-10-10T08:36:44.628079Z",
     "shell.execute_reply": "2025-10-10T08:36:44.627367Z",
     "shell.execute_reply.started": "2025-10-10T06:56:35.001723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "========================================================\n",
      "    STARTING 3-FOLD CV FOR CLASS: lighting_panel\n",
      "========================================================\n",
      "\n",
      "--- Starting Fold 1/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/lighting_panel/fold_1/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/lighting_panel/fold_1/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 1. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 11:56:44 AM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 0.7263, Acc: 0.5376\n",
      "Val   | Loss: 0.6802, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.6883, Acc: 0.5680\n",
      "Val   | Loss: 0.6816, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.6796, Acc: 0.5824\n",
      "Val   | Loss: 0.6725, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.6797, Acc: 0.5558\n",
      "Val   | Loss: 0.6903, Acc: 0.4416, F1: 0.5974\n",
      "New best model saved for fold 1 with F1 score: 0.5974\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.6813, Acc: 0.5953\n",
      "Val   | Loss: 0.6707, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.6800, Acc: 0.6036\n",
      "Val   | Loss: 0.6706, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.7020, Acc: 0.5763\n",
      "Val   | Loss: 0.6805, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.6082, Acc: 0.6811\n",
      "Val   | Loss: 0.7359, Acc: 0.6692, F1: 0.3354\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.2522, Acc: 0.8785\n",
      "Val   | Loss: 0.0888, Acc: 0.9772, F1: 0.9727\n",
      "New best model saved for fold 1 with F1 score: 0.9727\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.1531, Acc: 0.9484\n",
      "Val   | Loss: 0.0729, Acc: 0.9818, F1: 0.9785\n",
      "New best model saved for fold 1 with F1 score: 0.9785\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.1108, Acc: 0.9704\n",
      "Val   | Loss: 0.1172, Acc: 0.9742, F1: 0.9685\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.1218, Acc: 0.9628\n",
      "Val   | Loss: 0.1422, Acc: 0.9636, F1: 0.9552\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.2131, Acc: 0.9552\n",
      "Val   | Loss: 0.3456, Acc: 0.8467, F1: 0.7740\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.1362, Acc: 0.9537\n",
      "Val   | Loss: 0.1036, Acc: 0.9499, F1: 0.9359\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.0475, Acc: 0.9825\n",
      "Val   | Loss: 0.0195, Acc: 0.9909, F1: 0.9889\n",
      "New best model saved for fold 1 with F1 score: 0.9889\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.0147, Acc: 0.9947\n",
      "Val   | Loss: 0.0136, Acc: 0.9985, F1: 0.9982\n",
      "New best model saved for fold 1 with F1 score: 0.9982\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.0127, Acc: 0.9977\n",
      "Val   | Loss: 0.0026, Acc: 0.9985, F1: 0.9982\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.0001, Acc: 1.0000\n",
      "Val   | Loss: 0.0009, Acc: 1.0000, F1: 1.0000\n",
      "New best model saved for fold 1 with F1 score: 1.0000\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0008, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0003, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0026, Acc: 0.9985, F1: 0.9982\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0006, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0008, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0005, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0004, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0002, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0001, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0001, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0001, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.0000, Acc: 1.0000\n",
      "Val   | Loss: 0.0000, Acc: 1.0000, F1: 1.0000\n",
      "\n",
      "--- Training for Fold 1 Finished ---\n",
      "End Time (Lahore): 2025-10-10 12:14:48 PM\n",
      "Best validation F1 for this fold: 1.0000\n",
      "\n",
      "--- Starting Fold 2/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/lighting_panel/fold_2/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/lighting_panel/fold_2/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 2. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 12:14:55 PM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 0.7249, Acc: 0.5528\n",
      "Val   | Loss: 0.6849, Acc: 0.4355, F1: 0.5948\n",
      "New best model saved for fold 2 with F1 score: 0.5948\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.6794, Acc: 0.5801\n",
      "Val   | Loss: 0.6758, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.7075, Acc: 0.5809\n",
      "Val   | Loss: 0.6860, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.7165, Acc: 0.5771\n",
      "Val   | Loss: 0.8928, Acc: 0.4143, F1: 0.5858\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.7001, Acc: 0.5816\n",
      "Val   | Loss: 0.6759, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.6711, Acc: 0.5877\n",
      "Val   | Loss: 0.6698, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.7205, Acc: 0.7130\n",
      "Val   | Loss: 0.9305, Acc: 0.4143, F1: 0.5858\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.7002, Acc: 0.5756\n",
      "Val   | Loss: 0.6794, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.6955, Acc: 0.5892\n",
      "Val   | Loss: 0.6778, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.6905, Acc: 0.5740\n",
      "Val   | Loss: 0.6890, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.6845, Acc: 0.5930\n",
      "Val   | Loss: 0.6898, Acc: 0.5873, F1: 0.0073\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.7019, Acc: 0.5718\n",
      "Val   | Loss: 0.6805, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.6865, Acc: 0.5771\n",
      "Val   | Loss: 0.6737, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.6803, Acc: 0.5778\n",
      "Val   | Loss: 0.6792, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.6833, Acc: 0.5710\n",
      "Val   | Loss: 0.6722, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.7086, Acc: 0.5839\n",
      "Val   | Loss: 0.6805, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.6895, Acc: 0.5725\n",
      "Val   | Loss: 0.6781, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.6973, Acc: 0.5976\n",
      "Val   | Loss: 0.6810, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.6872, Acc: 0.5831\n",
      "Val   | Loss: 0.6817, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.6833, Acc: 0.5831\n",
      "Val   | Loss: 0.6789, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.6788, Acc: 0.5862\n",
      "Val   | Loss: 0.6802, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 0.6790, Acc: 0.5862\n",
      "Val   | Loss: 0.6787, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.6787, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.6787, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.6787, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.6790, Acc: 0.5862\n",
      "Val   | Loss: 0.6785, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.6788, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.6785, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.6785, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.6791, Acc: 0.5862\n",
      "Val   | Loss: 0.6786, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.6784, Acc: 0.5862\n",
      "Val   | Loss: 0.6785, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6785, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6785, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.6784, Acc: 0.5862\n",
      "Val   | Loss: 0.6785, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.6783, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.6782, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.6782, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.6782, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.6782, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.6782, Acc: 0.5862\n",
      "Val   | Loss: 0.6784, Acc: 0.5857, F1: 0.0000\n",
      "\n",
      "--- Training for Fold 2 Finished ---\n",
      "End Time (Lahore): 2025-10-10 12:32:45 PM\n",
      "Best validation F1 for this fold: 0.5948\n",
      "\n",
      "--- Starting Fold 3/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/lighting_panel/fold_3/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/lighting_panel/fold_3/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 3. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 12:32:53 PM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 0.8233, Acc: 0.5486\n",
      "Val   | Loss: 0.6916, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.6945, Acc: 0.5463\n",
      "Val   | Loss: 0.6914, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.6902, Acc: 0.5379\n",
      "Val   | Loss: 0.6888, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.6785, Acc: 0.6039\n",
      "Val   | Loss: 0.6884, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.6909, Acc: 0.5941\n",
      "Val   | Loss: 0.6868, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.6906, Acc: 0.5819\n",
      "Val   | Loss: 0.6796, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.6813, Acc: 0.5857\n",
      "Val   | Loss: 0.6795, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.6797, Acc: 0.5857\n",
      "Val   | Loss: 0.6749, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.6825, Acc: 0.5819\n",
      "Val   | Loss: 0.6767, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.6834, Acc: 0.5766\n",
      "Val   | Loss: 0.6825, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.6812, Acc: 0.5850\n",
      "Val   | Loss: 0.6800, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.6794, Acc: 0.5797\n",
      "Val   | Loss: 0.6790, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.6786, Acc: 0.5857\n",
      "Val   | Loss: 0.6853, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.6760, Acc: 0.5842\n",
      "Val   | Loss: 0.6625, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.6867, Acc: 0.5865\n",
      "Val   | Loss: 0.6783, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.6827, Acc: 0.6123\n",
      "Val   | Loss: 0.6660, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.6482, Acc: 0.6442\n",
      "Val   | Loss: 0.6506, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.6946, Acc: 0.5971\n",
      "Val   | Loss: 0.4109, Acc: 0.8739, F1: 0.8483\n",
      "New best model saved for fold 3 with F1 score: 0.8483\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.8937, Acc: 0.5918\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.7088, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.7050, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 0.7022, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.7000, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.6981, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.6965, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.6952, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.6940, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.6930, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.6920, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.6912, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.6906, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.6906, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.6905, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.6904, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.6903, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.6903, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.6902, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.6901, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.6898, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.6896, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.6895, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.6895, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.6895, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.6895, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.6895, Acc: 0.5857\n",
      "Val   | Loss: 0.6781, Acc: 0.5866, F1: 0.0000\n",
      "\n",
      "--- Training for Fold 3 Finished ---\n",
      "End Time (Lahore): 2025-10-10 12:50:51 PM\n",
      "Best validation F1 for this fold: 0.8483\n",
      "\n",
      "--- Average Cross-Validation F1 Score for 'lighting_panel': 0.8143 ---\n",
      "\n",
      "========================================================\n",
      "    STARTING 3-FOLD CV FOR CLASS: shifted_grab_handle\n",
      "========================================================\n",
      "\n",
      "--- Starting Fold 1/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/shifted_grab_handle/fold_1/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/shifted_grab_handle/fold_1/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 1. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 12:50:53 PM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 0.8174, Acc: 0.4504\n",
      "Val   | Loss: 0.7012, Acc: 0.5248, F1: 0.6884\n",
      "New best model saved for fold 1 with F1 score: 0.6884\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.7110, Acc: 0.4894\n",
      "Val   | Loss: 0.7030, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.7027, Acc: 0.4929\n",
      "Val   | Loss: 0.6939, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.6960, Acc: 0.4752\n",
      "Val   | Loss: 0.6934, Acc: 0.4184, F1: 0.4744\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.6986, Acc: 0.4645\n",
      "Val   | Loss: 0.6923, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.7000, Acc: 0.4752\n",
      "Val   | Loss: 0.6947, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.6988, Acc: 0.5000\n",
      "Val   | Loss: 0.6953, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.6988, Acc: 0.4929\n",
      "Val   | Loss: 0.6944, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.7036, Acc: 0.4752\n",
      "Val   | Loss: 0.6941, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.6981, Acc: 0.4787\n",
      "Val   | Loss: 0.6968, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.6973, Acc: 0.4752\n",
      "Val   | Loss: 0.6933, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.7045, Acc: 0.4894\n",
      "Val   | Loss: 0.6930, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.7026, Acc: 0.5035\n",
      "Val   | Loss: 0.6924, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.6967, Acc: 0.4858\n",
      "Val   | Loss: 0.6938, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.6957, Acc: 0.4397\n",
      "Val   | Loss: 0.6934, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.6955, Acc: 0.5142\n",
      "Val   | Loss: 0.6920, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.6944, Acc: 0.4929\n",
      "Val   | Loss: 0.6919, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.6946, Acc: 0.5248\n",
      "Val   | Loss: 0.6901, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.6919, Acc: 0.5248\n",
      "Val   | Loss: 0.6641, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.6784, Acc: 0.5248\n",
      "Val   | Loss: 0.6596, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.6754, Acc: 0.5248\n",
      "Val   | Loss: 27.3602, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 2.4622, Acc: 0.4965\n",
      "Val   | Loss: 0.6935, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.7368, Acc: 0.4681\n",
      "Val   | Loss: 0.6927, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.7372, Acc: 0.5071\n",
      "Val   | Loss: 0.6926, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.7358, Acc: 0.5248\n",
      "Val   | Loss: 0.6925, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.7345, Acc: 0.5248\n",
      "Val   | Loss: 0.6924, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.7335, Acc: 0.5248\n",
      "Val   | Loss: 0.6923, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.7325, Acc: 0.5248\n",
      "Val   | Loss: 0.6923, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.7316, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.7309, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.7304, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.7303, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.7302, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.7302, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.7301, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.7300, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.7300, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.7299, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.7298, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.7298, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.7297, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.7297, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.7296, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.7295, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.7295, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.7294, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.7294, Acc: 0.5248\n",
      "Val   | Loss: 0.6921, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.7294, Acc: 0.5248\n",
      "Val   | Loss: 0.6921, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.7294, Acc: 0.5248\n",
      "Val   | Loss: 0.6921, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.7294, Acc: 0.5248\n",
      "Val   | Loss: 0.6921, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Training for Fold 1 Finished ---\n",
      "End Time (Lahore): 2025-10-10 12:55:54 PM\n",
      "Best validation F1 for this fold: 0.6884\n",
      "\n",
      "--- Starting Fold 2/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/shifted_grab_handle/fold_2/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/shifted_grab_handle/fold_2/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 2. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 12:55:56 PM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 0.9223, Acc: 0.5035\n",
      "Val   | Loss: 0.7287, Acc: 0.5248, F1: 0.6884\n",
      "New best model saved for fold 2 with F1 score: 0.6884\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.6996, Acc: 0.5284\n",
      "Val   | Loss: 0.6997, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.7194, Acc: 0.5390\n",
      "Val   | Loss: 0.7467, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.6978, Acc: 0.5035\n",
      "Val   | Loss: 0.6984, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.6980, Acc: 0.5319\n",
      "Val   | Loss: 0.6928, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.6974, Acc: 0.4574\n",
      "Val   | Loss: 0.6932, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.6985, Acc: 0.5248\n",
      "Val   | Loss: 0.6916, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.6938, Acc: 0.5248\n",
      "Val   | Loss: 0.6926, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.6967, Acc: 0.5000\n",
      "Val   | Loss: 0.6924, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.6907, Acc: 0.5248\n",
      "Val   | Loss: 0.6927, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.6938, Acc: 0.5035\n",
      "Val   | Loss: 0.7001, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.7003, Acc: 0.5638\n",
      "Val   | Loss: 0.7604, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.7006, Acc: 0.5248\n",
      "Val   | Loss: 0.6913, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.6962, Acc: 0.5248\n",
      "Val   | Loss: 0.6911, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.7009, Acc: 0.5461\n",
      "Val   | Loss: 0.6924, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.6981, Acc: 0.5390\n",
      "Val   | Loss: 0.6923, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.6933, Acc: 0.5248\n",
      "Val   | Loss: 0.6927, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5532\n",
      "Val   | Loss: 0.6923, Acc: 0.4823, F1: 0.6473\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.7400, Acc: 0.4929\n",
      "Val   | Loss: 0.7016, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.7120, Acc: 0.4681\n",
      "Val   | Loss: 0.6921, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.6961, Acc: 0.5248\n",
      "Val   | Loss: 0.7054, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 0.6971, Acc: 0.5071\n",
      "Val   | Loss: 0.6939, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.6980, Acc: 0.4965\n",
      "Val   | Loss: 0.6948, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.6934, Acc: 0.4894\n",
      "Val   | Loss: 0.6921, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.6934, Acc: 0.5248\n",
      "Val   | Loss: 0.6932, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.6939, Acc: 0.5248\n",
      "Val   | Loss: 0.6920, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.6932, Acc: 0.5248\n",
      "Val   | Loss: 0.6911, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.6944, Acc: 0.4610\n",
      "Val   | Loss: 0.6942, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.6934, Acc: 0.5000\n",
      "Val   | Loss: 0.6921, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.6931, Acc: 0.5000\n",
      "Val   | Loss: 0.6920, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.6924, Acc: 0.5248\n",
      "Val   | Loss: 0.6920, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.6921, Acc: 0.5248\n",
      "Val   | Loss: 0.6920, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.6920, Acc: 0.5248\n",
      "Val   | Loss: 0.6920, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.6921, Acc: 0.5248\n",
      "Val   | Loss: 0.6920, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.6921, Acc: 0.5248\n",
      "Val   | Loss: 0.6919, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.6923, Acc: 0.5248\n",
      "Val   | Loss: 0.6919, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.6920, Acc: 0.5248\n",
      "Val   | Loss: 0.6918, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.6920, Acc: 0.5248\n",
      "Val   | Loss: 0.6917, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.6920, Acc: 0.5248\n",
      "Val   | Loss: 0.6916, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.6916, Acc: 0.5248\n",
      "Val   | Loss: 0.6912, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.6919, Acc: 0.5248\n",
      "Val   | Loss: 0.6908, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.6909, Acc: 0.5248\n",
      "Val   | Loss: 0.6902, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.6895, Acc: 0.5248\n",
      "Val   | Loss: 0.6857, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.6978, Acc: 0.6028\n",
      "Val   | Loss: 0.7549, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.7065, Acc: 0.5000\n",
      "Val   | Loss: 0.6979, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.6930, Acc: 0.5248\n",
      "Val   | Loss: 0.6968, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.6926, Acc: 0.5248\n",
      "Val   | Loss: 0.6960, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.6924, Acc: 0.5248\n",
      "Val   | Loss: 0.6956, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.6920, Acc: 0.5248\n",
      "Val   | Loss: 0.6950, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.6917, Acc: 0.5248\n",
      "Val   | Loss: 0.6944, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Training for Fold 2 Finished ---\n",
      "End Time (Lahore): 2025-10-10 01:01:03 PM\n",
      "Best validation F1 for this fold: 0.6884\n",
      "\n",
      "--- Starting Fold 3/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/shifted_grab_handle/fold_3/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/shifted_grab_handle/fold_3/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 3. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 01:01:06 PM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 1.2952, Acc: 0.5248\n",
      "Val   | Loss: 0.8446, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.7317, Acc: 0.4716\n",
      "Val   | Loss: 0.6985, Acc: 0.5248, F1: 0.6884\n",
      "New best model saved for fold 3 with F1 score: 0.6884\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.7004, Acc: 0.4823\n",
      "Val   | Loss: 0.6984, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.6966, Acc: 0.4787\n",
      "Val   | Loss: 0.6967, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.7169, Acc: 0.5745\n",
      "Val   | Loss: 0.6959, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.7052, Acc: 0.4291\n",
      "Val   | Loss: 0.7014, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.6953, Acc: 0.5319\n",
      "Val   | Loss: 0.6943, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.6952, Acc: 0.4752\n",
      "Val   | Loss: 0.6923, Acc: 0.7163, F1: 0.7753\n",
      "New best model saved for fold 3 with F1 score: 0.7753\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.6950, Acc: 0.5284\n",
      "Val   | Loss: 0.6914, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.6918, Acc: 0.5248\n",
      "Val   | Loss: 0.6862, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.6871, Acc: 0.5177\n",
      "Val   | Loss: 0.6936, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.6975, Acc: 0.5035\n",
      "Val   | Loss: 0.6933, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.6960, Acc: 0.4681\n",
      "Val   | Loss: 0.6924, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.6938, Acc: 0.5248\n",
      "Val   | Loss: 0.6914, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.6907, Acc: 0.5745\n",
      "Val   | Loss: 0.6923, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.6954, Acc: 0.4858\n",
      "Val   | Loss: 0.6930, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.6934, Acc: 0.5248\n",
      "Val   | Loss: 0.6923, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.7362, Acc: 0.5284\n",
      "Val   | Loss: 0.6972, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.7004, Acc: 0.5248\n",
      "Val   | Loss: 0.6927, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.6986, Acc: 0.5106\n",
      "Val   | Loss: 0.6993, Acc: 0.4752, F1: 0.0000\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.6942, Acc: 0.5284\n",
      "Val   | Loss: 0.6972, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 0.6947, Acc: 0.5248\n",
      "Val   | Loss: 0.6920, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.6955, Acc: 0.5248\n",
      "Val   | Loss: 0.6925, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.6990, Acc: 0.4752\n",
      "Val   | Loss: 0.6923, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.6958, Acc: 0.5248\n",
      "Val   | Loss: 0.6922, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.6950, Acc: 0.4894\n",
      "Val   | Loss: 0.6918, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.6923, Acc: 0.5248\n",
      "Val   | Loss: 0.6928, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.6943, Acc: 0.5248\n",
      "Val   | Loss: 0.6941, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.6937, Acc: 0.5248\n",
      "Val   | Loss: 0.6916, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.6924, Acc: 0.5248\n",
      "Val   | Loss: 0.6917, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.6915, Acc: 0.5248\n",
      "Val   | Loss: 0.6915, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.6914, Acc: 0.5248\n",
      "Val   | Loss: 0.6914, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.6915, Acc: 0.5248\n",
      "Val   | Loss: 0.6916, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.6910, Acc: 0.5248\n",
      "Val   | Loss: 0.6912, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.6911, Acc: 0.5248\n",
      "Val   | Loss: 0.6908, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.6904, Acc: 0.5248\n",
      "Val   | Loss: 0.6902, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.6904, Acc: 0.5248\n",
      "Val   | Loss: 0.6894, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.6908, Acc: 0.5248\n",
      "Val   | Loss: 0.6893, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.6902, Acc: 0.5248\n",
      "Val   | Loss: 0.6880, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.6886, Acc: 0.5248\n",
      "Val   | Loss: 0.6862, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.6871, Acc: 0.5248\n",
      "Val   | Loss: 0.6838, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.6854, Acc: 0.5248\n",
      "Val   | Loss: 0.6826, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.6851, Acc: 0.5248\n",
      "Val   | Loss: 0.6762, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.6804, Acc: 0.5248\n",
      "Val   | Loss: 0.6701, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.6664, Acc: 0.5248\n",
      "Val   | Loss: 0.6612, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.6549, Acc: 0.5248\n",
      "Val   | Loss: 0.6504, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.6481, Acc: 0.5248\n",
      "Val   | Loss: 0.6442, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.6414, Acc: 0.5248\n",
      "Val   | Loss: 0.6419, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.6354, Acc: 0.5248\n",
      "Val   | Loss: 0.6331, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.6292, Acc: 0.5248\n",
      "Val   | Loss: 0.6269, Acc: 0.5248, F1: 0.6884\n",
      "\n",
      "--- Training for Fold 3 Finished ---\n",
      "End Time (Lahore): 2025-10-10 01:06:07 PM\n",
      "Best validation F1 for this fold: 0.7753\n",
      "\n",
      "--- Average Cross-Validation F1 Score for 'shifted_grab_handle': 0.7173 ---\n",
      "\n",
      "========================================================\n",
      "    STARTING 3-FOLD CV FOR CLASS: frosted_window\n",
      "========================================================\n",
      "\n",
      "--- Starting Fold 1/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/frosted_window/fold_1/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/frosted_window/fold_1/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 1. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 01:06:12 PM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 0.8769, Acc: 0.5000\n",
      "Val   | Loss: 0.6941, Acc: 0.4474, F1: 0.6182\n",
      "New best model saved for fold 1 with F1 score: 0.6182\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.6965, Acc: 0.5220\n",
      "Val   | Loss: 0.6902, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.6911, Acc: 0.5396\n",
      "Val   | Loss: 0.6908, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.6930, Acc: 0.5279\n",
      "Val   | Loss: 0.6893, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.6906, Acc: 0.5352\n",
      "Val   | Loss: 0.6950, Acc: 0.4591, F1: 0.6293\n",
      "New best model saved for fold 1 with F1 score: 0.6293\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.6922, Acc: 0.5411\n",
      "Val   | Loss: 0.6884, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.6905, Acc: 0.5367\n",
      "Val   | Loss: 0.6866, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.6941, Acc: 0.5088\n",
      "Val   | Loss: 0.6921, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.6961, Acc: 0.5249\n",
      "Val   | Loss: 0.7086, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.6918, Acc: 0.5381\n",
      "Val   | Loss: 0.6830, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.6981, Acc: 0.5264\n",
      "Val   | Loss: 0.6974, Acc: 0.4591, F1: 0.6293\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.6962, Acc: 0.5176\n",
      "Val   | Loss: 0.6990, Acc: 0.4591, F1: 0.6293\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.6912, Acc: 0.5191\n",
      "Val   | Loss: 0.7116, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.6941, Acc: 0.5337\n",
      "Val   | Loss: 0.7381, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.6922, Acc: 0.5411\n",
      "Val   | Loss: 0.6979, Acc: 0.4591, F1: 0.6293\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.6971, Acc: 0.5323\n",
      "Val   | Loss: 0.6902, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.6975, Acc: 0.5117\n",
      "Val   | Loss: 0.6926, Acc: 0.5439, F1: 0.2277\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.6945, Acc: 0.5279\n",
      "Val   | Loss: 0.6902, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.6928, Acc: 0.5396\n",
      "Val   | Loss: 0.6899, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5469\n",
      "Val   | Loss: 0.6901, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.6914, Acc: 0.5396\n",
      "Val   | Loss: 0.6899, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 0.6906, Acc: 0.5396\n",
      "Val   | Loss: 0.6898, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.6907, Acc: 0.5396\n",
      "Val   | Loss: 0.6898, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.6905, Acc: 0.5396\n",
      "Val   | Loss: 0.6900, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.6903, Acc: 0.5396\n",
      "Val   | Loss: 0.6898, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5425\n",
      "Val   | Loss: 0.6912, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.6930, Acc: 0.5396\n",
      "Val   | Loss: 0.6902, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.6909, Acc: 0.5396\n",
      "Val   | Loss: 0.6898, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.6905, Acc: 0.5396\n",
      "Val   | Loss: 0.6899, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.6904, Acc: 0.5396\n",
      "Val   | Loss: 0.6897, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5396\n",
      "Val   | Loss: 0.6897, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5396\n",
      "Val   | Loss: 0.6897, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.6894, Acc: 0.5396\n",
      "Val   | Loss: 0.6896, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.6892, Acc: 0.5396\n",
      "Val   | Loss: 0.6895, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.6891, Acc: 0.5396\n",
      "Val   | Loss: 0.6892, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.6881, Acc: 0.5396\n",
      "Val   | Loss: 0.6886, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.6859, Acc: 0.5411\n",
      "Val   | Loss: 0.6863, Acc: 0.5409, F1: 0.0000\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.6837, Acc: 0.5821\n",
      "Val   | Loss: 0.6862, Acc: 0.6374, F1: 0.6026\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.6739, Acc: 0.5909\n",
      "Val   | Loss: 0.6793, Acc: 0.5556, F1: 0.0617\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.6313, Acc: 0.6188\n",
      "Val   | Loss: 0.5919, Acc: 0.6784, F1: 0.5089\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.5287, Acc: 0.7214\n",
      "Val   | Loss: 0.4782, Acc: 0.7865, F1: 0.7345\n",
      "New best model saved for fold 1 with F1 score: 0.7345\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.4003, Acc: 0.8182\n",
      "Val   | Loss: 0.4138, Acc: 0.7982, F1: 0.7988\n",
      "New best model saved for fold 1 with F1 score: 0.7988\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.3409, Acc: 0.8402\n",
      "Val   | Loss: 0.3666, Acc: 0.8596, F1: 0.8333\n",
      "New best model saved for fold 1 with F1 score: 0.8333\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.2632, Acc: 0.8959\n",
      "Val   | Loss: 0.5765, Acc: 0.7573, F1: 0.7798\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.2856, Acc: 0.8798\n",
      "Val   | Loss: 0.2462, Acc: 0.9006, F1: 0.8882\n",
      "New best model saved for fold 1 with F1 score: 0.8882\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.1670, Acc: 0.9252\n",
      "Val   | Loss: 0.2155, Acc: 0.9181, F1: 0.9097\n",
      "New best model saved for fold 1 with F1 score: 0.9097\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.1367, Acc: 0.9501\n",
      "Val   | Loss: 0.2117, Acc: 0.9094, F1: 0.8990\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.1210, Acc: 0.9619\n",
      "Val   | Loss: 0.2072, Acc: 0.9269, F1: 0.9196\n",
      "New best model saved for fold 1 with F1 score: 0.9196\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.1128, Acc: 0.9663\n",
      "Val   | Loss: 0.2320, Acc: 0.9211, F1: 0.9115\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.0993, Acc: 0.9721\n",
      "Val   | Loss: 0.2152, Acc: 0.9269, F1: 0.9180\n",
      "\n",
      "--- Training for Fold 1 Finished ---\n",
      "End Time (Lahore): 2025-10-10 01:16:26 PM\n",
      "Best validation F1 for this fold: 0.9196\n",
      "\n",
      "--- Starting Fold 2/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/frosted_window/fold_2/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/frosted_window/fold_2/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 2. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 01:16:30 PM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 0.7569, Acc: 0.4729\n",
      "Val   | Loss: 0.7081, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.7025, Acc: 0.5051\n",
      "Val   | Loss: 0.6910, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.6978, Acc: 0.5183\n",
      "Val   | Loss: 0.6901, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.6994, Acc: 0.5256\n",
      "Val   | Loss: 0.6910, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.6942, Acc: 0.5344\n",
      "Val   | Loss: 0.8430, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.7000, Acc: 0.5066\n",
      "Val   | Loss: 0.6898, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.6914, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.6916, Acc: 0.5403\n",
      "Val   | Loss: 0.6905, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.6905, Acc: 0.5403\n",
      "Val   | Loss: 0.6887, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.6916, Acc: 0.5403\n",
      "Val   | Loss: 0.6919, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.6973, Acc: 0.5095\n",
      "Val   | Loss: 0.6939, Acc: 0.4604, F1: 0.6305\n",
      "New best model saved for fold 2 with F1 score: 0.6305\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.6948, Acc: 0.5359\n",
      "Val   | Loss: 0.6903, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.6988, Acc: 0.5154\n",
      "Val   | Loss: 0.7007, Acc: 0.4604, F1: 0.6305\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.6925, Acc: 0.5388\n",
      "Val   | Loss: 0.7771, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.6906, Acc: 0.5403\n",
      "Val   | Loss: 0.6927, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.6927, Acc: 0.5403\n",
      "Val   | Loss: 0.6902, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.6921, Acc: 0.5417\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.6905, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.6907, Acc: 0.5403\n",
      "Val   | Loss: 0.6897, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.6908, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.6912, Acc: 0.5403\n",
      "Val   | Loss: 0.6898, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 0.6912, Acc: 0.5403\n",
      "Val   | Loss: 0.6917, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.6917, Acc: 0.5403\n",
      "Val   | Loss: 0.6905, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.6909, Acc: 0.5403\n",
      "Val   | Loss: 0.6901, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.6904, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.6907, Acc: 0.5403\n",
      "Val   | Loss: 0.6897, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.7288, Acc: 0.5403\n",
      "Val   | Loss: 0.6907, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.7183, Acc: 0.5520\n",
      "Val   | Loss: 0.6935, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.6952, Acc: 0.5403\n",
      "Val   | Loss: 0.6906, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.6903, Acc: 0.5403\n",
      "Val   | Loss: 0.6924, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.6912, Acc: 0.5403\n",
      "Val   | Loss: 0.6902, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.6901, Acc: 0.5403\n",
      "Val   | Loss: 0.6903, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6902, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.6902, Acc: 0.5403\n",
      "Val   | Loss: 0.6902, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6901, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6901, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.6901, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.6901, Acc: 0.5403\n",
      "Val   | Loss: 0.6901, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Training for Fold 2 Finished ---\n",
      "End Time (Lahore): 2025-10-10 01:26:34 PM\n",
      "Best validation F1 for this fold: 0.6305\n",
      "\n",
      "--- Starting Fold 3/3 ---\n",
      "Loading data from processed_data_multi_class_3_fold/frosted_window/fold_3/train_data.pkl...\n",
      "Data loaded successfully.\n",
      "Loading data from processed_data_multi_class_3_fold/frosted_window/fold_3/val_data.pkl...\n",
      "Data loaded successfully.\n",
      "ℹ️ No checkpoint found for fold 3. Starting from scratch.\n",
      "Start Time (Lahore): 2025-10-10 01:26:39 PM\n",
      "\n",
      "--- Epoch 1/50 ---\n",
      "Train | Loss: 1.0436, Acc: 0.5286\n",
      "Val   | Loss: 0.7046, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 2/50 ---\n",
      "Train | Loss: 0.6937, Acc: 0.5403\n",
      "Val   | Loss: 0.6896, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 3/50 ---\n",
      "Train | Loss: 0.6930, Acc: 0.5315\n",
      "Val   | Loss: 0.6948, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 4/50 ---\n",
      "Train | Loss: 0.6961, Acc: 0.5168\n",
      "Val   | Loss: 0.6941, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 5/50 ---\n",
      "Train | Loss: 0.6927, Acc: 0.5124\n",
      "Val   | Loss: 0.6889, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 6/50 ---\n",
      "Train | Loss: 0.6968, Acc: 0.5359\n",
      "Val   | Loss: 0.7055, Acc: 0.4604, F1: 0.6305\n",
      "New best model saved for fold 3 with F1 score: 0.6305\n",
      "\n",
      "--- Epoch 7/50 ---\n",
      "Train | Loss: 0.7046, Acc: 0.4597\n",
      "Val   | Loss: 0.6937, Acc: 0.4604, F1: 0.6305\n",
      "\n",
      "--- Epoch 8/50 ---\n",
      "Train | Loss: 0.6938, Acc: 0.5315\n",
      "Val   | Loss: 0.6897, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 9/50 ---\n",
      "Train | Loss: 0.6915, Acc: 0.5403\n",
      "Val   | Loss: 0.6896, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 10/50 ---\n",
      "Train | Loss: 0.6911, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 11/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6868, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 12/50 ---\n",
      "Train | Loss: 0.6932, Acc: 0.5403\n",
      "Val   | Loss: 0.6843, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 13/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5637\n",
      "Val   | Loss: 0.6928, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 14/50 ---\n",
      "Train | Loss: 0.6960, Acc: 0.5198\n",
      "Val   | Loss: 0.6910, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 15/50 ---\n",
      "Train | Loss: 0.6923, Acc: 0.5403\n",
      "Val   | Loss: 0.6893, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 16/50 ---\n",
      "Train | Loss: 0.6918, Acc: 0.5403\n",
      "Val   | Loss: 0.6889, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 17/50 ---\n",
      "Train | Loss: 0.6912, Acc: 0.5403\n",
      "Val   | Loss: 0.6878, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 18/50 ---\n",
      "Train | Loss: 0.6906, Acc: 0.5403\n",
      "Val   | Loss: 0.6868, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 19/50 ---\n",
      "Train | Loss: 0.6919, Acc: 0.5403\n",
      "Val   | Loss: 0.6904, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 20/50 ---\n",
      "Train | Loss: 0.6919, Acc: 0.5403\n",
      "Val   | Loss: 0.6883, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 21/50 ---\n",
      "Train | Loss: 0.6908, Acc: 0.5403\n",
      "Val   | Loss: 0.6881, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 22/50 ---\n",
      "Train | Loss: 0.6884, Acc: 0.5403\n",
      "Val   | Loss: 0.6865, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 23/50 ---\n",
      "Train | Loss: 0.6830, Acc: 0.5403\n",
      "Val   | Loss: 0.6835, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 24/50 ---\n",
      "Train | Loss: 0.6834, Acc: 0.5403\n",
      "Val   | Loss: 0.6908, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 25/50 ---\n",
      "Train | Loss: 0.6929, Acc: 0.5403\n",
      "Val   | Loss: 0.6920, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 26/50 ---\n",
      "Train | Loss: 0.6929, Acc: 0.5403\n",
      "Val   | Loss: 0.6913, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 27/50 ---\n",
      "Train | Loss: 0.6923, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 28/50 ---\n",
      "Train | Loss: 0.6933, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 29/50 ---\n",
      "Train | Loss: 0.6915, Acc: 0.5403\n",
      "Val   | Loss: 0.6902, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 30/50 ---\n",
      "Train | Loss: 0.6907, Acc: 0.5403\n",
      "Val   | Loss: 0.6901, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 31/50 ---\n",
      "Train | Loss: 0.6907, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 32/50 ---\n",
      "Train | Loss: 0.6900, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 33/50 ---\n",
      "Train | Loss: 0.6898, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 34/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 35/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 36/50 ---\n",
      "Train | Loss: 0.6898, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 37/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 38/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5403\n",
      "Val   | Loss: 0.6902, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 39/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5403\n",
      "Val   | Loss: 0.6905, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 40/50 ---\n",
      "Train | Loss: 0.6901, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 41/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 42/50 ---\n",
      "Train | Loss: 0.6897, Acc: 0.5403\n",
      "Val   | Loss: 0.6900, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 43/50 ---\n",
      "Train | Loss: 0.6895, Acc: 0.5403\n",
      "Val   | Loss: 0.6901, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 44/50 ---\n",
      "Train | Loss: 0.6899, Acc: 0.5403\n",
      "Val   | Loss: 0.6902, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 45/50 ---\n",
      "Train | Loss: 0.6894, Acc: 0.5403\n",
      "Val   | Loss: 0.6898, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 46/50 ---\n",
      "Train | Loss: 0.6894, Acc: 0.5403\n",
      "Val   | Loss: 0.6898, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 47/50 ---\n",
      "Train | Loss: 0.6894, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 48/50 ---\n",
      "Train | Loss: 0.6893, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 49/50 ---\n",
      "Train | Loss: 0.6893, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Epoch 50/50 ---\n",
      "Train | Loss: 0.6893, Acc: 0.5403\n",
      "Val   | Loss: 0.6899, Acc: 0.5396, F1: 0.0000\n",
      "\n",
      "--- Training for Fold 3 Finished ---\n",
      "End Time (Lahore): 2025-10-10 01:36:44 PM\n",
      "Best validation F1 for this fold: 0.6305\n",
      "\n",
      "--- Average Cross-Validation F1 Score for 'frosted_window': 0.7269 ---\n",
      "\n",
      "========================================================\n",
      "           ALL CROSS-VALIDATION RUNS COMPLETE\n",
      "========================================================\n",
      "  - Average F1 Score for 'lighting_panel': 0.8143\n",
      "  - Average F1 Score for 'shifted_grab_handle': 0.7173\n",
      "  - Average F1 Score for 'frosted_window': 0.7269\n",
      "========================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# --- Assume these are defined elsewhere ---\n",
    "# from config import config \n",
    "# from model import ADLModel\n",
    "# from dataset import PreprocessedDataset\n",
    "# from training_utils import train_one_epoch, validate, plot_metrics\n",
    "# pk_timezone = pytz.timezone(\"Asia/Karachi\")\n",
    "\n",
    "def run_cross_validation_experiment():\n",
    "    \"\"\"\n",
    "    Main function to run the entire training and 3-fold cross-validation process.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Store the final averaged results for each class\n",
    "    final_class_results = {}\n",
    "\n",
    "    for class_name in config.CLASS_NAMES:\n",
    "        print(f\"\\n========================================================\")\n",
    "        print(f\"    STARTING {config.N_FOLDS}-FOLD CV FOR CLASS: {class_name}\")\n",
    "        print(f\"========================================================\")\n",
    "        \n",
    "        class_data_dir = os.path.join(config.base_data_dir, class_name)\n",
    "        class_output_dir = os.path.join(config.base_output_dir, class_name)\n",
    "        \n",
    "        # Store the best F1 score from each fold for the current class\n",
    "        fold_performance_scores = []\n",
    "\n",
    "        # --- NEW: Outer loop for iterating through each fold ---\n",
    "        for fold_idx in range(1, config.N_FOLDS + 1):\n",
    "            print(f\"\\n--- Starting Fold {fold_idx}/{config.N_FOLDS} ---\")\n",
    "\n",
    "            # --- MODIFIED: Paths now point to the specific fold's data and output ---\n",
    "            current_data_dir = os.path.join(class_data_dir, f'fold_{fold_idx}')\n",
    "            current_output_dir = os.path.join(class_output_dir, f'fold_{fold_idx}')\n",
    "            os.makedirs(current_output_dir, exist_ok=True)\n",
    "            \n",
    "            # --- Data Loading for the current fold ---\n",
    "            train_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'train_data.pkl'))\n",
    "            val_dataset = PreprocessedDataset(os.path.join(current_data_dir, 'val_data.pkl'))\n",
    "            train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)\n",
    "\n",
    "            # --- IMPORTANT: Re-initialize model and optimizer for each fold ---\n",
    "            model = ADLModel(config.num_classes, config.drop_rate, config.drop_threshold).to(device)\n",
    "            optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "            scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45], gamma=0.1)\n",
    "            criterion_cls = nn.CrossEntropyLoss()\n",
    "\n",
    "            # --- Checkpoint Loading Logic (now fold-specific) ---\n",
    "            checkpoint_path = os.path.join(current_output_dir, 'checkpoint.pth')\n",
    "            start_epoch = 0\n",
    "            best_val_f1 = 0.0 # Using F1 score as the key metric\n",
    "            history = {\n",
    "                'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [],\n",
    "                'val_precision': [], 'val_recall': [], 'val_f1': []\n",
    "            }\n",
    "\n",
    "            if os.path.exists(checkpoint_path):\n",
    "                print(f\"✅ Resuming training for fold {fold_idx} from checkpoint.\")\n",
    "                checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "                model.load_state_dict(checkpoint['model_state_dict'])\n",
    "                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "                scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "                start_epoch = checkpoint['epoch'] + 1\n",
    "                history = checkpoint['history']\n",
    "                best_val_f1 = checkpoint['best_val_metric']\n",
    "                print(f\"   Resumed from epoch {start_epoch}. Best F1 so far: {best_val_f1:.4f}\")\n",
    "            else:\n",
    "                print(f\"ℹ️ No checkpoint found for fold {fold_idx}. Starting from scratch.\")\n",
    "\n",
    "            # --- Training Loop for Epochs ---\n",
    "            start_time_pk = datetime.now(pk_timezone)\n",
    "            print(f\"Start Time (Lahore): {start_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "\n",
    "            for epoch in range(start_epoch, config.epochs):\n",
    "                print(f\"\\n--- Epoch {epoch+1}/{config.epochs} ---\")\n",
    "                \n",
    "                train_metrics = train_one_epoch(model, train_loader, criterion_cls, optimizer, device, config.adl_alpha)\n",
    "                val_metrics = validate(model, val_loader, criterion_cls, device)\n",
    "                \n",
    "                # Log metrics to history\n",
    "                history['train_loss'].append(train_metrics['loss'])\n",
    "                history['train_acc'].append(train_metrics['accuracy'])\n",
    "                history['val_loss'].append(val_metrics['loss'])\n",
    "                history['val_acc'].append(val_metrics['accuracy'])\n",
    "                history['val_precision'].append(val_metrics['precision'])\n",
    "                history['val_recall'].append(val_metrics['recall'])\n",
    "                history['val_f1'].append(val_metrics['f1_score'])\n",
    "                \n",
    "                print(f\"Train | Loss: {train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}\")\n",
    "                print(f\"Val   | Loss: {val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f}, F1: {val_metrics['f1_score']:.4f}\")\n",
    "                \n",
    "                scheduler.step()\n",
    "\n",
    "                # Save the best model based on F1 score\n",
    "                if val_metrics['f1_score'] > best_val_f1:\n",
    "                    best_val_f1 = val_metrics['f1_score']\n",
    "                    torch.save(model.state_dict(), os.path.join(current_output_dir, 'best_model.pth'))\n",
    "                    print(f\"New best model saved for fold {fold_idx} with F1 score: {best_val_f1:.4f}\")\n",
    "\n",
    "                # Save checkpoint after each epoch\n",
    "                torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'best_val_metric': best_val_f1,\n",
    "                    'history': history,\n",
    "                }, checkpoint_path)\n",
    "\n",
    "            end_time_pk = datetime.now(pk_timezone)\n",
    "            print(f\"\\n--- Training for Fold {fold_idx} Finished ---\")\n",
    "            print(f\"End Time (Lahore): {end_time_pk.strftime('%Y-%m-%d %I:%M:%S %p')}\")\n",
    "            print(f\"Best validation F1 for this fold: {best_val_f1:.4f}\")\n",
    "            \n",
    "            # --- Store the best result for this fold ---\n",
    "            fold_performance_scores.append(best_val_f1)\n",
    "            \n",
    "            # --- Save Metrics and Plots for the fold ---\n",
    "            # You can add your plotting and metrics saving logic here\n",
    "            # Example: plot_metrics(history, current_output_dir)\n",
    "\n",
    "        # --- Aggregate and report the final average score for the class ---\n",
    "        if fold_performance_scores:\n",
    "            average_score = sum(fold_performance_scores) / len(fold_performance_scores)\n",
    "            final_class_results[class_name] = average_score\n",
    "            print(f\"\\n--- Average Cross-Validation F1 Score for '{class_name}': {average_score:.4f} ---\")\n",
    "        else:\n",
    "            print(f\"\\n--- No folds were successfully trained for '{class_name}' ---\")\n",
    "\n",
    "\n",
    "    # --- Final Summary ---\n",
    "    print(\"\\n========================================================\")\n",
    "    print(\"           ALL CROSS-VALIDATION RUNS COMPLETE\")\n",
    "    print(\"========================================================\")\n",
    "    for class_name, avg_score in final_class_results.items():\n",
    "        print(f\"  - Average F1 Score for '{class_name}': {avg_score:.4f}\")\n",
    "    print(\"========================================================\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Ensure you have a 'config' object available, loaded from your Config class.\n",
    "    run_cross_validation_experiment()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7721e62-af61-4e2c-b675-fe29db4bcf72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-09T13:09:13.189699Z",
     "iopub.status.busy": "2025-10-09T13:09:13.189419Z",
     "iopub.status.idle": "2025-10-09T13:09:13.281856Z",
     "shell.execute_reply": "2025-10-09T13:09:13.281292Z",
     "shell.execute_reply.started": "2025-10-09T13:09:13.189673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Metrics for 'frosted_window' saved to trained_models_multi_class/frosted_window/fold_3/frosted_window_training_history.csv ---\n",
      "\n",
      "--- Generating plots for frosted_window ---\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "import pandas as pd\n",
    "  \n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': [],\n",
    "        'val_precision': [], 'val_recall': [], 'val_f1': []\n",
    "    }\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.index.name = 'epoch'\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "csv_path = os.path.join(current_output_dir, f'{class_name}_training_history.csv')\n",
    "history_df.to_csv(csv_path)\n",
    "print(f\"\\n--- Metrics for '{class_name}' saved to {csv_path} ---\")\n",
    "\n",
    "print(f\"\\n--- Generating plots for {class_name} ---\")\n",
    "# plot_metrics(history, class_name, current_output_dir)\n",
    "# if best_val_metrics:\n",
    "#         plot_confusion_matrix(best_val_metrics['labels'], best_val_metrics['predictions'], class_name, current_output_dir)\n",
    "#         print(\"\\n--- Final Classification Report (Best Model) ---\")\n",
    "#         print(classification_report(best_val_metrics['labels'], best_val_metrics['predictions'], target_names=['non-defect', 'defect']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07500f5-a79f-4dac-a0f5-894c48079a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1812ee-a66a-4252-8369-ed4624cc13c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
